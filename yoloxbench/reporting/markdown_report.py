"""Create a rich Markdown report (tables + plots) from a YOLOxBench tester CSV.
Usage
-----
$ yox report cmp_runs/test_2x2.csv
Outputs a folder:
  cmp_runs/test_2x2_report/
      report.md
      bar_map50.png
      bar_map5095.png
      pr_curves/
      confusion_matrices/
"""
from __future__ import annotations
from pathlib import Path
from datetime import datetime
import shutil
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

ASSETS = [
    ("metrics/mAP50", "bar_map50.png", "mAP@0.5"),
    ("metrics/mAP50-95", "bar_map5095.png", "mAP@0.5:0.95"),
]

_MD_HEADER = """# 📋 YOLOxBench Comparison Report

*Generated: {date}*

**Models:** {models}

**Datasets:** {datasets}

---

## 📊 Aggregate Metrics

| Rank | Model | Dataset | mAP50 | mAP50‑95 | Precision | Recall |
|------|-------|---------|-------|----------|-----------|--------|
{summary_rows}

---

## 🏆 Leaderboards

![mAP50 Bar]({bar_map50})

![mAP50‑95 Bar]({bar_map5095})

---

## 📈 Precision‑Recall Curves
{pr_rows}

---
## 🔀 Confusion Matrices
{cm_rows}

---
> *Report auto‑generated by **YOLOxBench**.*
"""


def _ensure(p: Path):
    p.mkdir(parents=True, exist_ok=True)
    return p


def _plot_bar(df: pd.DataFrame, metric: str, out: Path):
    plt.figure(figsize=(8, 4))
    df.sort_values(metric, ascending=False).plot.bar(
        x="run", y=metric, legend=False, ax=plt.gca())
    plt.ylabel(metric)
    plt.tight_layout()
    plt.savefig(out)
    plt.close()


def make_markdown(csv_path: Path) -> Path:
    csv_path = Path(csv_path)
    df = pd.read_csv(csv_path)

    report_dir = _ensure(csv_path.with_suffix("_report"))

    # ---------------- leaderboards ----------------
    for metr, fname, _ in ASSETS:
        if metr in df.columns:
            _plot_bar(df.assign(run=df.model+"|"+df.dataset), metr, report_dir/fname)

    # ---------------- PR & CM copies ----------------
    pr_rows, cm_rows = [], []
    pr_dir = _ensure(report_dir/"pr_curves")
    cm_dir = _ensure(report_dir/"confusion_matrices")

    for _, row in df.iterrows():
        run_dir = Path(row["run_dir"]) if "run_dir" in row else None
        tag = f"{row.model}_{row.dataset}".replace("/", "-")
        # PR curve
        pr_src = run_dir/"PR_curve.png" if run_dir else None
        if pr_src and pr_src.exists():
            pr_dst = pr_dir/f"{tag}.png"; shutil.copy(pr_src, pr_dst)
            pr_rows.append(f"![{tag}]({pr_dst.relative_to(report_dir)})")
        # Confusion matrix
        cm_src = run_dir/"confusion_matrix.png" if run_dir else None
        if cm_src and cm_src.exists():
            cm_dst = cm_dir/f"{tag}.png"; shutil.copy(cm_src, cm_dst)
            cm_rows.append(f"![{tag}]({cm_dst.relative_to(report_dir)})")

    # ---------------- summary table ----------------
    df_sorted = df.sort_values("metrics/mAP50", ascending=False)
    summary_rows = "\n".join(
        f"| {i+1} | `{r.model}` | `{r.dataset}` | {r['metrics/mAP50']:.3f} | {r['metrics/mAP50-95']:.3f} | {r['metrics/precision']:.3f} | {r['metrics/recall']:.3f} |"
        for i, r in enumerate(df_sorted.itertuples())
    )

    md = _MD_HEADER.format(
        date=datetime.now().strftime("%Y‑%m‑d %H:%M"),
        models=", ".join(df.model.unique()),
        datasets=", ".join(df.dataset.unique()),
        summary_rows=summary_rows,
        bar_map50=ASSETS[0][1],
        bar_map5095=ASSETS[1][1],
        pr_rows="\n".join(pr_rows) or "_PR curves unavailable (images not found)_",
        cm_rows="\n".join(cm_rows) or "_Confusion matrices unavailable (images not found)_",
    )

    report_path = report_dir/"report.md"
    report_path.write_text(md, encoding="utf-8")
    return report_path